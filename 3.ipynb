{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgadDiWqlrQm"
      },
      "source": [
        "## Import libraries\r\n",
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from tensorflow import keras\r\n",
        "from keras.datasets import mnist\r\n",
        "from tensorflow.keras import layers\r\n",
        "from keras.layers import Dense, Conv2D, Flatten\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZD5l8_loM3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72bdda9a-b6a2-4dfe-b1dd-25aed76722bc"
      },
      "source": [
        "# Load test and train data\r\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqHV41mevSQC",
        "outputId": "d7899101-b945-4b97-8904-a9adc9ec58f5"
      },
      "source": [
        "# Understanding test and train data\r\n",
        "print(type(X_train))\r\n",
        "print(type(Y_train))\r\n",
        "print(type(X_test))\r\n",
        "print(type(Y_test))\r\n",
        "\r\n",
        "print(X_train.shape) \r\n",
        "print(Y_train.shape) \r\n",
        "print(X_test.shape) \r\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKIhKDERwhK1",
        "outputId": "d37b5325-1173-454f-80c9-9c5835491f6f"
      },
      "source": [
        "X_train = np.expand_dims(X_train, -1)\r\n",
        "X_test = np.expand_dims(X_test, -1)\r\n",
        "\r\n",
        "X_train = X_train.astype('float32')\r\n",
        "X_test = X_test.astype('float32')\r\n",
        "\r\n",
        "# check the min and max values\r\n",
        "np.min(X_train), np.max(X_train)\r\n",
        "#np.min(Y_train), np.max(Y_test)\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 255.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyUT4V14ygWA",
        "outputId": "ef0d2c04-49bc-419a-f22e-349d9700b003"
      },
      "source": [
        "# Normalize the data\r\n",
        "X_train /= 255\r\n",
        "X_test /= 255\r\n",
        "\r\n",
        "# Check min and max values\r\n",
        "np.min(X_train), np.max(X_train)\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaYwCAPszowS"
      },
      "source": [
        "# make y data categorical\r\n",
        "no_of_classes = 10\r\n",
        "Y_train = keras.utils.to_categorical(Y_train, no_of_classes)\r\n",
        "Y_test = keras.utils.to_categorical(Y_test, no_of_classes)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTSgsETS4XUz",
        "outputId": "594eb76b-5b74-46d9-f361-2867decf67ed"
      },
      "source": [
        "# Train the model from section 1 with 0.25 noise factor\r\n",
        "# Model1\r\n",
        "model1 = keras.Sequential()\r\n",
        "\r\n",
        "# Add Layers\r\n",
        "model1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\n",
        "model1.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model1.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model1.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model1.add(Flatten())\r\n",
        "model1.add(Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "# Model1 summary\r\n",
        "model1.summary()\r\n",
        "\r\n",
        "# Compile the model1\r\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# Add noise\r\n",
        "noise_factor = 0.25\r\n",
        "X_train_noisy_25 = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\r\n",
        "X_test_noisy_25 = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\r\n",
        "X_train_noisy_25 = np.clip(X_train_noisy_25, 0. , 1.)\r\n",
        "X_test_noisy_25 = np.clip(X_test_noisy_25, 0. , 1.)\r\n",
        "\r\n",
        "# Fit the model1 with \r\n",
        "model1.fit(X_train_noisy_25, Y_train, batch_size=128, epochs=15, validation_split=0.1)\r\n",
        "\r\n",
        "# Evaluate the model1\r\n",
        "score = model1.evaluate(X_test_noisy_25, Y_test, verbose=0)\r\n",
        "print(\"Model accuracy: \", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                16010     \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "422/422 [==============================] - 37s 85ms/step - loss: 0.8152 - accuracy: 0.7631 - val_loss: 0.1197 - val_accuracy: 0.9665\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.1203 - accuracy: 0.9639 - val_loss: 0.0830 - val_accuracy: 0.9737\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.0810 - accuracy: 0.9752 - val_loss: 0.0684 - val_accuracy: 0.9802\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 34s 82ms/step - loss: 0.0683 - accuracy: 0.9786 - val_loss: 0.0656 - val_accuracy: 0.9800\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 34s 81ms/step - loss: 0.0569 - accuracy: 0.9826 - val_loss: 0.0599 - val_accuracy: 0.9818\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 34s 81ms/step - loss: 0.0488 - accuracy: 0.9846 - val_loss: 0.0612 - val_accuracy: 0.9825\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 34s 81ms/step - loss: 0.0458 - accuracy: 0.9855 - val_loss: 0.0576 - val_accuracy: 0.9837\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 34s 81ms/step - loss: 0.0386 - accuracy: 0.9881 - val_loss: 0.0484 - val_accuracy: 0.9865\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 34s 81ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: 0.0529 - val_accuracy: 0.9842\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 34s 81ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.0520 - val_accuracy: 0.9855\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 35s 82ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.0521 - val_accuracy: 0.9858\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 34s 81ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0503 - val_accuracy: 0.9872\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 34s 81ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.0592 - val_accuracy: 0.9838\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 34s 81ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.0500 - val_accuracy: 0.9870\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 34s 81ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 0.0530 - val_accuracy: 0.9873\n",
            "Model accuracy:  0.9850000143051147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj4aGtWgJLgT",
        "outputId": "0014f1cb-62c4-4be1-9dce-3bdcb845557d"
      },
      "source": [
        "# Train the model from section 1 with 0.25 noise factor. Add 1 more layer\r\n",
        "# Model2\r\n",
        "model2 = keras.Sequential()\r\n",
        "\r\n",
        "# Add Layers\r\n",
        "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model2.add(Flatten())\r\n",
        "model2.add(Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "# Model2 summary\r\n",
        "model2.summary()\r\n",
        "\r\n",
        "# Compile the model2\r\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# Add noise\r\n",
        "noise_factor = 0.25\r\n",
        "X_train_noisy_25 = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\r\n",
        "X_test_noisy_25 = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\r\n",
        "X_train_noisy_25 = np.clip(X_train_noisy_25, 0. , 1.)\r\n",
        "X_test_noisy_25 = np.clip(X_test_noisy_25, 0. , 1.)\r\n",
        "\r\n",
        "# Fit the model2 with \r\n",
        "model2.fit(X_train_noisy_25, Y_train, batch_size=128, epochs=15, validation_split=0.1)\r\n",
        "\r\n",
        "# Evaluate the model2\r\n",
        "score = model2.evaluate(X_test_noisy_25, Y_test, verbose=0)\r\n",
        "print(\"Model accuracy: \", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 56,394\n",
            "Trainable params: 56,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "422/422 [==============================] - 39s 92ms/step - loss: 0.9603 - accuracy: 0.7051 - val_loss: 0.1689 - val_accuracy: 0.9522\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 38s 91ms/step - loss: 0.1604 - accuracy: 0.9511 - val_loss: 0.1076 - val_accuracy: 0.9673\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 38s 91ms/step - loss: 0.1128 - accuracy: 0.9640 - val_loss: 0.0947 - val_accuracy: 0.9713\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0829 - accuracy: 0.9748 - val_loss: 0.0778 - val_accuracy: 0.9778\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 38s 91ms/step - loss: 0.0689 - accuracy: 0.9779 - val_loss: 0.0717 - val_accuracy: 0.9798\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 38s 91ms/step - loss: 0.0599 - accuracy: 0.9818 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0506 - accuracy: 0.9839 - val_loss: 0.0650 - val_accuracy: 0.9810\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0418 - accuracy: 0.9874 - val_loss: 0.0712 - val_accuracy: 0.9775\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 0.0681 - val_accuracy: 0.9787\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 0.0770 - val_accuracy: 0.9792\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0284 - accuracy: 0.9910 - val_loss: 0.0658 - val_accuracy: 0.9820\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.0647 - val_accuracy: 0.9830\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 0.0655 - val_accuracy: 0.9810\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 38s 91ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.0645 - val_accuracy: 0.9823\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0708 - val_accuracy: 0.9813\n",
            "Model accuracy:  0.98089998960495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj0TnLi_JuEG",
        "outputId": "1d0d23f5-aff9-4e42-c8b3-1d3d630d7a70"
      },
      "source": [
        "# Train the model from section 1 with 0.25 noise factor. Add 2 layers\r\n",
        "# Model1\r\n",
        "model3 = keras.Sequential()\r\n",
        "\r\n",
        "# Add Layers\r\n",
        "model3.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\n",
        "model3.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model3.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model3.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model3.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model3.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model3.add(Flatten())\r\n",
        "model3.add(Dense(20, activation='softmax'))\r\n",
        "model3.add(Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "# Model3 summary\r\n",
        "model3.summary()\r\n",
        "\r\n",
        "# Compile the model3\r\n",
        "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# Add noise\r\n",
        "noise_factor = 0.25\r\n",
        "X_train_noisy_25 = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\r\n",
        "X_test_noisy_25 = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\r\n",
        "X_train_noisy_25 = np.clip(X_train_noisy_25, 0. , 1.)\r\n",
        "X_test_noisy_25 = np.clip(X_test_noisy_25, 0. , 1.)\r\n",
        "\r\n",
        "# Fit the model3 with \r\n",
        "model3.fit(X_train_noisy_25, Y_train, batch_size=128, epochs=15, validation_split=0.1)\r\n",
        "\r\n",
        "# Evaluate the model3\r\n",
        "score = model3.evaluate(X_test_noisy_25, Y_test, verbose=0)\r\n",
        "print(\"Model accuracy: \", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 20)                1300      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 57,254\n",
            "Trainable params: 57,254\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "422/422 [==============================] - 39s 91ms/step - loss: 2.0982 - accuracy: 0.2438 - val_loss: 1.7194 - val_accuracy: 0.3847\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 38s 91ms/step - loss: 1.6306 - accuracy: 0.3921 - val_loss: 1.4236 - val_accuracy: 0.3950\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 38s 91ms/step - loss: 1.3753 - accuracy: 0.4021 - val_loss: 1.2773 - val_accuracy: 0.4032\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 1.2457 - accuracy: 0.4094 - val_loss: 1.1964 - val_accuracy: 0.4080\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 38s 91ms/step - loss: 1.1702 - accuracy: 0.4028 - val_loss: 1.1562 - val_accuracy: 0.4040\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 1.1284 - accuracy: 0.4098 - val_loss: 1.1154 - val_accuracy: 0.4062\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 1.0969 - accuracy: 0.4062 - val_loss: 1.0949 - val_accuracy: 0.4070\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 38s 91ms/step - loss: 1.0710 - accuracy: 0.4080 - val_loss: 1.0770 - val_accuracy: 0.4075\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 1.0497 - accuracy: 0.4104 - val_loss: 1.0784 - val_accuracy: 0.4048\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 1.0450 - accuracy: 0.4095 - val_loss: 1.0622 - val_accuracy: 0.4053\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 1.0273 - accuracy: 0.4117 - val_loss: 1.0606 - val_accuracy: 0.4090\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 1.0214 - accuracy: 0.4162 - val_loss: 1.0483 - val_accuracy: 0.3992\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 1.0191 - accuracy: 0.4159 - val_loss: 1.0471 - val_accuracy: 0.4060\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 1.0064 - accuracy: 0.4172 - val_loss: 1.0430 - val_accuracy: 0.4063\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 38s 90ms/step - loss: 1.0066 - accuracy: 0.4172 - val_loss: 1.0403 - val_accuracy: 0.4072\n",
            "Model accuracy:  0.4169999957084656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxI5bf0fPRt-",
        "outputId": "16100be1-709f-4c14-8bd9-feb8701deea1"
      },
      "source": [
        "# Train the model from section 1 with 0.25 noise factor. Add one conv layer and one dense layers\r\n",
        "# Model4\r\n",
        "model4 = keras.Sequential()\r\n",
        "\r\n",
        "# Add Layers\r\n",
        "model4.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\n",
        "model4.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model4.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model4.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model4.add(Flatten())\r\n",
        "model4.add(Dense(20, activation='softmax'))\r\n",
        "model4.add(Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "# Model4 summary\r\n",
        "model4.summary()\r\n",
        "\r\n",
        "# Compile the model4\r\n",
        "model4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# Add noise\r\n",
        "noise_factor = 0.25\r\n",
        "X_train_noisy_25 = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\r\n",
        "X_test_noisy_25 = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\r\n",
        "X_train_noisy_25 = np.clip(X_train_noisy_25, 0. , 1.)\r\n",
        "X_test_noisy_25 = np.clip(X_test_noisy_25, 0. , 1.)\r\n",
        "\r\n",
        "# Fit the model4 with \r\n",
        "model4.fit(X_train_noisy_25, Y_train, batch_size=128, epochs=15, validation_split=0.1)\r\n",
        "\r\n",
        "# Evaluate the model4\r\n",
        "score = model4.evaluate(X_test_noisy_25, Y_test, verbose=0)\r\n",
        "print(\"Model accuracy: \", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 20)                32020     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 51,046\n",
            "Trainable params: 51,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "422/422 [==============================] - 37s 87ms/step - loss: 1.9956 - accuracy: 0.4974 - val_loss: 1.4306 - val_accuracy: 0.7703\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 1.3241 - accuracy: 0.7745 - val_loss: 1.0037 - val_accuracy: 0.7892\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.9454 - accuracy: 0.7853 - val_loss: 0.7690 - val_accuracy: 0.7905\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.7125 - accuracy: 0.7975 - val_loss: 0.6041 - val_accuracy: 0.7950\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.5819 - accuracy: 0.7971 - val_loss: 0.5127 - val_accuracy: 0.7985\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.4944 - accuracy: 0.8012 - val_loss: 0.4586 - val_accuracy: 0.7980\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.4426 - accuracy: 0.8007 - val_loss: 0.4182 - val_accuracy: 0.7990\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.4089 - accuracy: 0.8035 - val_loss: 0.3920 - val_accuracy: 0.8002\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 35s 82ms/step - loss: 0.3792 - accuracy: 0.8055 - val_loss: 0.3790 - val_accuracy: 0.8002\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.3587 - accuracy: 0.8103 - val_loss: 0.3611 - val_accuracy: 0.8010\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.3426 - accuracy: 0.8077 - val_loss: 0.3590 - val_accuracy: 0.8125\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.3329 - accuracy: 0.8108 - val_loss: 0.3428 - val_accuracy: 0.8098\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 35s 83ms/step - loss: 0.3234 - accuracy: 0.8142 - val_loss: 0.3358 - val_accuracy: 0.8332\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 35s 82ms/step - loss: 0.3019 - accuracy: 0.8492 - val_loss: 0.2635 - val_accuracy: 0.8947\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 35s 82ms/step - loss: 0.2235 - accuracy: 0.9001 - val_loss: 0.2293 - val_accuracy: 0.8960\n",
            "Model accuracy:  0.8973000049591064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teBBPZUTTHqX",
        "outputId": "f770e2f4-f8ae-4f68-9bab-dce0e8ebe9eb"
      },
      "source": [
        "# Train the model from section 1 with 0.25 noise factor. Add one conv layer and one dense layers\r\n",
        "# Model5\r\n",
        "model5 = keras.Sequential()\r\n",
        "\r\n",
        "# Add Layers\r\n",
        "model5.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\n",
        "model5.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model5.add(layers.Conv2D(16, (3, 3), activation='relu'))\r\n",
        "model5.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model5.add(layers.Conv2D(16, (3, 3), activation='relu'))\r\n",
        "model5.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model5.add(Flatten())\r\n",
        "model5.add(Dense(10, activation='softmax'))\r\n",
        "model5.add(Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "# Model5 summary\r\n",
        "model5.summary()\r\n",
        "\r\n",
        "# Compile the model5\r\n",
        "model5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# Add noise\r\n",
        "noise_factor = 0.25\r\n",
        "X_train_noisy_25 = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\r\n",
        "X_test_noisy_25 = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\r\n",
        "X_train_noisy_25 = np.clip(X_train_noisy_25, 0. , 1.)\r\n",
        "X_test_noisy_25 = np.clip(X_test_noisy_25, 0. , 1.)\r\n",
        "\r\n",
        "# Fit the model5 with \r\n",
        "model5.fit(X_train_noisy_25, Y_train, batch_size=128, epochs=15, validation_split=0.1)\r\n",
        "\r\n",
        "# Evaluate the model5\r\n",
        "score = model5.evaluate(X_test_noisy_25, Y_test, verbose=0)\r\n",
        "print(\"Model accuracy: \", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_23 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 11, 11, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 3, 3, 16)          2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 1, 1, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                170       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 7,544\n",
            "Trainable params: 7,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "422/422 [==============================] - 28s 64ms/step - loss: 2.1384 - accuracy: 0.2198 - val_loss: 1.7465 - val_accuracy: 0.4352\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 26s 63ms/step - loss: 1.6936 - accuracy: 0.4399 - val_loss: 1.4435 - val_accuracy: 0.4760\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 26s 63ms/step - loss: 1.4322 - accuracy: 0.4708 - val_loss: 1.2694 - val_accuracy: 0.4763\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 26s 63ms/step - loss: 1.2741 - accuracy: 0.4819 - val_loss: 1.1745 - val_accuracy: 0.5103\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 26s 62ms/step - loss: 1.1775 - accuracy: 0.4925 - val_loss: 1.1060 - val_accuracy: 0.5127\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 26s 62ms/step - loss: 1.1228 - accuracy: 0.4980 - val_loss: 1.0804 - val_accuracy: 0.4968\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 26s 62ms/step - loss: 1.0849 - accuracy: 0.4990 - val_loss: 1.0457 - val_accuracy: 0.4982\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 26s 61ms/step - loss: 1.0541 - accuracy: 0.5058 - val_loss: 1.0034 - val_accuracy: 0.5165\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 26s 62ms/step - loss: 1.0300 - accuracy: 0.5137 - val_loss: 0.9651 - val_accuracy: 0.5373\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 26s 62ms/step - loss: 0.9276 - accuracy: 0.6232 - val_loss: 0.7962 - val_accuracy: 0.6498\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 26s 62ms/step - loss: 0.7953 - accuracy: 0.6613 - val_loss: 0.7469 - val_accuracy: 0.6797\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 26s 62ms/step - loss: 0.7483 - accuracy: 0.6856 - val_loss: 0.7145 - val_accuracy: 0.7113\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 26s 61ms/step - loss: 0.7105 - accuracy: 0.7166 - val_loss: 0.6791 - val_accuracy: 0.7233\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 26s 61ms/step - loss: 0.6830 - accuracy: 0.7304 - val_loss: 0.6554 - val_accuracy: 0.7577\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 26s 61ms/step - loss: 0.6465 - accuracy: 0.7847 - val_loss: 0.5998 - val_accuracy: 0.8330\n",
            "Model accuracy:  0.8327999711036682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6uNxr7KWq62",
        "outputId": "59a9e1f7-e619-4143-9a93-d42289d0eb7b"
      },
      "source": [
        "# Train the model from section 1 with 0.25 noise factor. Add one conv layer and one dense layers\r\n",
        "# Model6\r\n",
        "model6 = keras.Sequential()\r\n",
        "\r\n",
        "# Add Layers\r\n",
        "model6.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\r\n",
        "model6.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model6.add(layers.Conv2D(32, (3, 3), activation='relu'))\r\n",
        "model6.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model6.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model6.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model6.add(Flatten())\r\n",
        "model6.add(Dense(10, activation='softmax'))\r\n",
        "model6.add(Dense(20, activation='softmax'))\r\n",
        "model6.add(Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "# Model6 summary\r\n",
        "model6.summary()\r\n",
        "\r\n",
        "# Compile the model6\r\n",
        "model6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "# Add noise\r\n",
        "noise_factor = 0.25\r\n",
        "X_train_noisy_25 = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\r\n",
        "X_test_noisy_25 = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\r\n",
        "X_train_noisy_25 = np.clip(X_train_noisy_25, 0. , 1.)\r\n",
        "X_test_noisy_25 = np.clip(X_test_noisy_25, 0. , 1.)\r\n",
        "\r\n",
        "# Fit the model6 with \r\n",
        "model6.fit(X_train_noisy_25, Y_train, batch_size=128, epochs=15, validation_split=0.1)\r\n",
        "\r\n",
        "# Evaluate the model6\r\n",
        "score = model6.evaluate(X_test_noisy_25, Y_test, verbose=0)\r\n",
        "print(\"Model accuracy: \", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_37 (Conv2D)           (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 10, 10, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 3, 3, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 29,656\n",
            "Trainable params: 29,656\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "422/422 [==============================] - 33s 77ms/step - loss: 2.2730 - accuracy: 0.1722 - val_loss: 2.0854 - val_accuracy: 0.3058\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 31s 73ms/step - loss: 1.9870 - accuracy: 0.3083 - val_loss: 1.7265 - val_accuracy: 0.3068\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 31s 73ms/step - loss: 1.6548 - accuracy: 0.3108 - val_loss: 1.5365 - val_accuracy: 0.3065\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 31s 72ms/step - loss: 1.4978 - accuracy: 0.3128 - val_loss: 1.4595 - val_accuracy: 0.3117\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 30s 72ms/step - loss: 1.4442 - accuracy: 0.3093 - val_loss: 1.4397 - val_accuracy: 0.3120\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 30s 72ms/step - loss: 1.4177 - accuracy: 0.3122 - val_loss: 1.4235 - val_accuracy: 0.3092\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 30s 72ms/step - loss: 1.4025 - accuracy: 0.3164 - val_loss: 1.4142 - val_accuracy: 0.3120\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 30s 72ms/step - loss: 1.3939 - accuracy: 0.3178 - val_loss: 1.4065 - val_accuracy: 0.3132\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 30s 72ms/step - loss: 1.3815 - accuracy: 0.3202 - val_loss: 1.4077 - val_accuracy: 0.3152\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 31s 72ms/step - loss: 1.3748 - accuracy: 0.3410 - val_loss: 1.3149 - val_accuracy: 0.4080\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 31s 74ms/step - loss: 1.2533 - accuracy: 0.4092 - val_loss: 1.2274 - val_accuracy: 0.4060\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 30s 71ms/step - loss: 1.1948 - accuracy: 0.4152 - val_loss: 1.2045 - val_accuracy: 0.4092\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 30s 71ms/step - loss: 1.1723 - accuracy: 0.4185 - val_loss: 1.1978 - val_accuracy: 0.4090\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 29s 70ms/step - loss: 1.1596 - accuracy: 0.4201 - val_loss: 1.1914 - val_accuracy: 0.4050\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 29s 70ms/step - loss: 1.1519 - accuracy: 0.4146 - val_loss: 1.1828 - val_accuracy: 0.4232\n",
            "Model accuracy:  0.42800000309944153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBlQzEDIABMD",
        "outputId": "0af9ea16-b7e0-4231-c425-bd21a5f61c9e"
      },
      "source": [
        "# Try with Autoencoders\r\n",
        "\r\n",
        "\r\n",
        "# Encoding\r\n",
        "input_img_shape = keras.Input(shape=(28, 28, 1))\r\n",
        "\r\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img_shape)\r\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\r\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\r\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\r\n",
        "\r\n",
        "# Decoding\r\n",
        "\r\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\r\n",
        "x = layers.UpSampling2D((2, 2))(x)\r\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\r\n",
        "x = layers.UpSampling2D((2, 2))(x)\r\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\r\n",
        "\r\n",
        "autoencoder = keras.Model(input_img_shape, decoded)\r\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\r\n",
        "\r\n",
        "# Add noise\r\n",
        "noise_factor = 0.25\r\n",
        "X_train_noisy_25 = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\r\n",
        "X_test_noisy_25 = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\r\n",
        "X_train_noisy_25 = np.clip(X_train_noisy_25, 0. , 1.)\r\n",
        "X_test_noisy_25 = np.clip(X_test_noisy_25, 0. , 1.)\r\n",
        "\r\n",
        "\r\n",
        "autoencoder.fit(X_train_noisy_25, X_train,\r\n",
        "                epochs=100,\r\n",
        "                batch_size=128,\r\n",
        "                shuffle=True,\r\n",
        "                validation_data=(X_test_noisy_25, X_test))\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 148s 314ms/step - loss: 0.2173 - val_loss: 0.0889\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0878 - val_loss: 0.0827\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0829 - val_loss: 0.0802\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0806 - val_loss: 0.0788\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 145s 310ms/step - loss: 0.0792 - val_loss: 0.0778\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0782 - val_loss: 0.0771\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 144s 307ms/step - loss: 0.0775 - val_loss: 0.0764\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 144s 308ms/step - loss: 0.0768 - val_loss: 0.0763\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 145s 310ms/step - loss: 0.0763 - val_loss: 0.0757\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 145s 308ms/step - loss: 0.0760 - val_loss: 0.0755\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 145s 308ms/step - loss: 0.0758 - val_loss: 0.0752\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0756 - val_loss: 0.0749\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0754 - val_loss: 0.0750\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0752 - val_loss: 0.0745\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 145s 310ms/step - loss: 0.0752 - val_loss: 0.0745\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0749 - val_loss: 0.0743\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0745 - val_loss: 0.0742\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 144s 306ms/step - loss: 0.0746 - val_loss: 0.0741\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 144s 308ms/step - loss: 0.0744 - val_loss: 0.0739\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 144s 308ms/step - loss: 0.0744 - val_loss: 0.0741\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 144s 308ms/step - loss: 0.0744 - val_loss: 0.0740\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 145s 308ms/step - loss: 0.0744 - val_loss: 0.0737\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 144s 307ms/step - loss: 0.0741 - val_loss: 0.0737\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0741 - val_loss: 0.0737\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 146s 310ms/step - loss: 0.0741 - val_loss: 0.0736\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 146s 310ms/step - loss: 0.0741 - val_loss: 0.0735\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0740 - val_loss: 0.0737\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 147s 313ms/step - loss: 0.0739 - val_loss: 0.0735\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 147s 313ms/step - loss: 0.0739 - val_loss: 0.0735\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 148s 316ms/step - loss: 0.0738 - val_loss: 0.0735\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0737 - val_loss: 0.0734\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 147s 314ms/step - loss: 0.0737 - val_loss: 0.0734\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 147s 313ms/step - loss: 0.0736 - val_loss: 0.0733\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 147s 313ms/step - loss: 0.0736 - val_loss: 0.0734\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0736 - val_loss: 0.0733\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0736 - val_loss: 0.0732\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 148s 316ms/step - loss: 0.0737 - val_loss: 0.0731\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 148s 315ms/step - loss: 0.0735 - val_loss: 0.0734\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0735 - val_loss: 0.0732\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0734 - val_loss: 0.0732\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0735 - val_loss: 0.0732\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 146s 310ms/step - loss: 0.0735 - val_loss: 0.0730\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 147s 313ms/step - loss: 0.0733 - val_loss: 0.0730\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0734 - val_loss: 0.0731\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 147s 314ms/step - loss: 0.0733 - val_loss: 0.0730\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0734 - val_loss: 0.0730\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 147s 313ms/step - loss: 0.0734 - val_loss: 0.0735\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 148s 315ms/step - loss: 0.0733 - val_loss: 0.0730\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 147s 313ms/step - loss: 0.0733 - val_loss: 0.0730\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 148s 315ms/step - loss: 0.0734 - val_loss: 0.0729\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0733 - val_loss: 0.0729\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0733 - val_loss: 0.0729\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 147s 313ms/step - loss: 0.0733 - val_loss: 0.0729\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0733 - val_loss: 0.0729\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0732 - val_loss: 0.0729\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0732 - val_loss: 0.0730\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0733 - val_loss: 0.0731\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 145s 310ms/step - loss: 0.0733 - val_loss: 0.0728\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 146s 310ms/step - loss: 0.0732 - val_loss: 0.0731\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 146s 310ms/step - loss: 0.0730 - val_loss: 0.0729\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0730 - val_loss: 0.0728\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0731 - val_loss: 0.0728\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0731 - val_loss: 0.0728\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0732 - val_loss: 0.0728\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 146s 310ms/step - loss: 0.0732 - val_loss: 0.0728\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0731 - val_loss: 0.0728\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0731 - val_loss: 0.0729\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0731 - val_loss: 0.0728\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 145s 310ms/step - loss: 0.0731 - val_loss: 0.0727\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 145s 310ms/step - loss: 0.0731 - val_loss: 0.0728\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0731 - val_loss: 0.0728\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 146s 310ms/step - loss: 0.0731 - val_loss: 0.0728\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0730 - val_loss: 0.0729\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0730 - val_loss: 0.0727\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0731 - val_loss: 0.0728\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0730 - val_loss: 0.0727\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0729 - val_loss: 0.0728\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 145s 310ms/step - loss: 0.0729 - val_loss: 0.0727\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 145s 310ms/step - loss: 0.0730 - val_loss: 0.0729\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0730 - val_loss: 0.0727\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0730 - val_loss: 0.0726\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0730 - val_loss: 0.0727\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0730 - val_loss: 0.0727\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0728 - val_loss: 0.0726\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 145s 310ms/step - loss: 0.0730 - val_loss: 0.0727\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 145s 310ms/step - loss: 0.0730 - val_loss: 0.0727\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 145s 309ms/step - loss: 0.0730 - val_loss: 0.0728\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 145s 310ms/step - loss: 0.0729 - val_loss: 0.0727\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0730 - val_loss: 0.0726\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0729 - val_loss: 0.0726\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0729 - val_loss: 0.0729\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0730 - val_loss: 0.0726\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 147s 312ms/step - loss: 0.0729 - val_loss: 0.0726\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0729 - val_loss: 0.0726\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0727 - val_loss: 0.0727\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 147s 313ms/step - loss: 0.0729 - val_loss: 0.0727\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 147s 313ms/step - loss: 0.0729 - val_loss: 0.0726\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 147s 312ms/step - loss: 0.0729 - val_loss: 0.0726\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 147s 314ms/step - loss: 0.0729 - val_loss: 0.0727\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0730 - val_loss: 0.0726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efc06623780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlgInf93_1AM"
      },
      "source": [
        "all_denoised_images = autoencoder.predict(X_test_noisy_25)\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mr7trB1__7i",
        "outputId": "05dc1a71-410b-4b71-82bc-042e4a132cae"
      },
      "source": [
        "test_loss  = autoencoder.evaluate(X_test_noisy_25, X_test, batch_size = 20)\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 7s 15ms/step - loss: 0.0726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuJlA2koAMlj",
        "outputId": "13160ad1-b9df-4607-f6b3-9b9440cb54fd"
      },
      "source": [
        "print(test_loss)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.07262732833623886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "M4_5IIg-AibT",
        "outputId": "a2d8b12b-978c-4845-dc26-3bcabe9f0a4d"
      },
      "source": [
        "dimension = X_train.shape[1]\r\n",
        "n = 3\r\n",
        "for i in range(n):\r\n",
        "    fig, axes = plt.subplots(1, 3)\r\n",
        "    fig.set_size_inches(8, 2)\r\n",
        "    axes[0].set_title('Noisy image')\r\n",
        "    im0 = axes[0].imshow(X_test_noisy_25[i].reshape(dimension, dimension), cmap = 'Reds')\r\n",
        "    axes[1].set_title('Target image')\r\n",
        "    im1 = axes[1].imshow(X_test[i].reshape(dimension, dimension), cmap = 'Reds')\r\n",
        "    axes[2].set_title('Denoised image')\r\n",
        "    im2 = axes[2].imshow(all_denoised_images[i].reshape(dimension, dimension), cmap = 'Reds')\r\n",
        "    plt.savefig(f'comparison-{i}.png')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x144 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x144 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x144 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}